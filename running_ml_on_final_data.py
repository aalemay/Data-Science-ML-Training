# -*- coding: utf-8 -*-
"""Running ML on Final Data

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1fvWaLDg1AIBQef7kNI5o6O7Ya3y4WCT0
"""

import pandas as pd
df_nfl = pd.read_csv('/content/nfl_data_more_real.csv')
df_mlb_previous = pd.read_csv("/content/MLB data.csv")
df_mlb_soccer = pd.read_csv('/content/new_sports_matches.csv')

df_nfl.drop(columns=['Time Zone'], inplace=True)
df_nfl["Team"] = "NFL"
df_nfl["AVG"] = df_nfl["AVG"].str.replace(",", "").astype(int)
df_nfl

df_mlb_soccer.drop(columns=["Datetime","Season"], inplace=True)
df_mlb_soccer

df_nfl.drop(columns=["Home Score","Away Score"], inplace=True)
df_nfl["City"] = df_nfl["CITY"]
df_nfl.drop(columns=["CITY"], inplace=True)

df_mlb_previous["AVG"].str.replace(",", "").astype(int)
df_mlb_previous.drop(columns=["Home Score","Away Score"], inplace=True)
df_mlb_previous["Date"] = df_mlb_previous["Date"].str.split("T").str[0]
df_mlb_previous["City"] = df_mlb_previous["CITY"]
df_mlb_previous["Team"] = "MLB"
df_mlb_previous.drop(columns=["CITY"], inplace=True)

df_mlb_soccer = pd.concat([df_mlb_previous, df_mlb_soccer])

from google.colab import files  # Only needed if using Google Colab

df_combo = pd.concat([df_nfl, df_mlb_soccer], axis=0)
df_combo["Time"] = df_combo["Time"].apply(lambda x: x.zfill(5))  # Ensures '0:09' â†’ '00:09'
df_combo["Datetime"] = pd.to_datetime(df_combo["Date"] + " " + df_combo["Time"], format="%Y-%m-%d %H:%M")

# Save DataFrame to CSV

df_combo

df_combo.to_csv("processed_data_BIG.csv", index=False)

files.download("processed_data_BIG.csv")

import pandas as pd
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.compose import make_column_transformer
from sklearn.pipeline import make_pipeline
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import cross_val_score

df_combined = df_combo

# Convert Datetime to numerical format (Unix timestamp)
df_combined["Datetime"] = pd.to_datetime(df_combined["Datetime"]).astype(int) // 10**9

# Convert "AVG" to numeric (removing commas)
df_combined["AVG"] = df_combined["AVG"].astype(str).str.replace(",", "").astype(float)

# Define Features and Target
features = ["Home Team", "Away Team", "City", "Team", "Datetime", "AVG"]
target = "Home Win"

# Create Preprocessing Transformer
transformer = make_column_transformer(
    (StandardScaler(), ["Datetime", "AVG"]),  # Numerical columns
    (OneHotEncoder(handle_unknown="ignore", sparse_output=False), ["Home Team", "Away Team", "City", "Team"]),  # Categorical columns
    remainder="drop"
)

# Create Pipeline
pipeline = make_pipeline(
    transformer,
    LogisticRegression(max_iter = 1000)
)

# Perform Cross-Validation
scores = cross_val_score(
    pipeline,
    X=df_combined[features].copy(),
    y=df_combined[target],
    scoring="f1_macro",
    cv=4
)

print(f"Features: {features}")
print(f"F1 Score: {scores.mean()}")

from sklearn.model_selection import GridSearchCV

param_grid = {
    "logisticregression__C": [0.01, 0.1, 1, 10, 100],  # Regularization strength
    "logisticregression__penalty": ["l1", "l2"],  # Lasso (L1) or Ridge (L2) regularization
    "logisticregression__solver": ["liblinear", "saga"]  # Solvers that support L1 and L2
}

grid_search = GridSearchCV(
    pipeline,
    param_grid,
    scoring="f1_macro",
    cv=4,
    n_jobs=-1  # Use all processors for speedup
)

# Fit Grid Search
grid_search.fit(df_combined[features], df_combined[target])

# Print Best Parameters and Score
print("Best Parameters:", grid_search.best_params_)
print("Best Cross-Validation Accuracy:", grid_search.best_score_)

from sklearn.ensemble import RandomForestClassifier
pipeline = make_pipeline(
    transformer,
    RandomForestClassifier(random_state=42)
)
param_grid = {
    'randomforestclassifier__n_estimators': [10, 50, 100, 200, 500],
    'randomforestclassifier__max_depth': [None, 10, 20, 30],
    'randomforestclassifier__min_samples_split': [2, 5, 10],
    'randomforestclassifier__min_samples_leaf': [1, 2, 4],
    'randomforestclassifier__max_features': ['sqrt', 'log2'],
    'randomforestclassifier__bootstrap': [True, False]
}
    # Grid search
grid_search = GridSearchCV(
    pipeline,
    param_grid,
    scoring="f1_macro",
    cv=4,
    n_jobs=-2
)

grid_search.fit(df_combined[features], df_combined[target])

# Print Best Parameters and Score
print("Best Parameters:", grid_search.best_params_)
print("Best Cross-Validation Accuracy:", grid_search.best_score_)

from sklearn.neighbors import KNeighborsClassifier

pipeline = make_pipeline(
    transformer,
    KNeighborsClassifier()
)
param_grid = {
    "kneighborsclassifier__n_neighbors": [3, 5, 7, 9, 11],
    "kneighborsclassifier__weights": ["uniform", "distance"],
    "kneighborsclassifier__metric": ["euclidean", "manhattan", "minkowski"]
}
    # Grid search
grid_search = GridSearchCV(
    pipeline,
    param_grid,
    scoring="f1_macro",
    cv=4,
    n_jobs=-1
)

grid_search.fit(df_combined[features], df_combined[target])

# Print Best Parameters and Score
print("Best Parameters:", grid_search.best_params_)
print("Best Cross-Validation Accuracy:", grid_search.best_score_)

from sklearn.tree import DecisionTreeClassifier
from sklearn.pipeline import make_pipeline

# Define pipeline
pipeline = make_pipeline(
    transformer,
    DecisionTreeClassifier(random_state=42)  # Set random_state for reproducibility
)

# Define hyperparameter grid for Decision Tree
param_grid = {
    "decisiontreeclassifier__criterion": ["gini", "entropy"],
    "decisiontreeclassifier__max_depth": [None, 5, 10, 20],
    "decisiontreeclassifier__min_samples_split": [2, 5, 10],
    "decisiontreeclassifier__min_samples_leaf": [1, 2, 5]
}

# Grid search
grid_search = GridSearchCV(
    pipeline,
    param_grid,
    scoring="f1_macro",
    cv=4,
    n_jobs=-1
)

# Fit model
grid_search.fit(df_combined[features], df_combined[target])

# Print Best Parameters and Score
print("Best Parameters:", grid_search.best_params_)
print("Best Cross-Validation Accuracy:", grid_search.best_score_)

import pandas as pd
import itertools
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import GridSearchCV

# Define feature set and target
all_features = ["Home Team", "Away Team", "City", "Team", "Datetime", "AVG"]
target = "Home Win"

# Generate all feature subset combinations
feature_subsets = []
for r in range(1, len(all_features) + 1):
    feature_subsets.extend(itertools.combinations(all_features, r))

# Define hyperparameter grid
param_grid = {
    "classifier__C": [0.01, 0.1, 1, 10, 100],
    "classifier__penalty": ["l1", "l2"],
    "classifier__solver": ["liblinear", "saga"]
}

best_score = -1
best_features = None
best_model = None

# Loop through different feature combinations
for feature_set in feature_subsets:
    feature_set = list(feature_set)

    # Separate numerical and categorical features
    numerical_features = [f for f in feature_set if f in ["Datetime", "AVG"]]
    categorical_features = [f for f in feature_set if f not in ["Datetime", "AVG"]]

    # Define the preprocessing transformer
    transformer = ColumnTransformer(
        transformers=[
            ("num", StandardScaler(), numerical_features),
            ("cat", OneHotEncoder(handle_unknown="ignore", sparse_output=False), categorical_features)
        ],
        remainder="drop"
    )

    # Define the pipeline correctly
    pipeline = Pipeline([
        ("preprocessor", transformer),
        ("classifier", LogisticRegression(max_iter=1000))
    ])

    # Use GridSearchCV to find the best parameters
    grid_search = GridSearchCV(
        pipeline,
        param_grid,
        scoring="f1_macro",
        cv=4,
        n_jobs=-1
    )

    grid_search.fit(df_combined[feature_set], df_combined[target])

    # Track best model
    if grid_search.best_score_ > best_score:
        best_score = grid_search.best_score_
        best_features = feature_set
        best_model = grid_search.best_estimator_

print("Best Feature Combination:", best_features)
print("Best Parameters:", best_model.named_steps["classifier"].get_params())
print("Best Cross-Validation Accuracy:", best_score)

import pandas as pd
import itertools
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import GridSearchCV

all_features = ["Home Team", "Away Team", "City", "Team", "Datetime", "AVG"]
target = "Home Win"

# Generate feature subsets (combinations of features)
feature_subsets = []
for r in range(1, len(all_features) + 1):
    feature_subsets.extend(itertools.combinations(all_features, r))

# Hyperparameter Grid for KNeighborsClassifier
param_grid = {
    "kneighborsclassifier__n_neighbors": [3, 5, 7, 9, 11],
    "kneighborsclassifier__weights": ["uniform", "distance"],
    "kneighborsclassifier__metric": ["euclidean", "manhattan", "minkowski"]
}

best_score = -1
best_features = None
best_model = None

# Loop through different feature combinations
for feature_set in feature_subsets:
    feature_set = list(feature_set)
    numerical_features = [f for f in feature_set if f in ["Datetime", "AVG"]]
    categorical_features = [f for f in feature_set if f not in ["Datetime", "AVG"]]

    transformer = ColumnTransformer(
        transformers=[
            ("num", StandardScaler(), numerical_features),
            ("cat", OneHotEncoder(handle_unknown="ignore", sparse_output=False), categorical_features)
        ],
        remainder="drop"
    )

    pipeline = Pipeline([
        ("preprocessor", transformer),
        ("kneighborsclassifier", KNeighborsClassifier())
    ])

    grid_search = GridSearchCV(
        pipeline,
        param_grid,
        scoring="f1_macro",
        cv=4,
        n_jobs=-1
    )

    grid_search.fit(df_combined[feature_set], df_combined[target])

    if grid_search.best_score_ > best_score:
        best_score = grid_search.best_score_
        best_features = feature_set
        best_model = grid_search.best_estimator_

print("Best Feature Combination:", best_features)
print("Best Parameters:", best_model.named_steps["kneighborsclassifier"].get_params())
print("Best Cross-Validation Accuracy:", best_score)

import pandas as pd
import itertools
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import GridSearchCV

all_features = ["Home Team", "Away Team", "City", "Team", "Datetime", "AVG"]
target = "Home Win"

# Generate feature subsets (combinations of features)
feature_subsets = []
for r in range(1, len(all_features) + 1):
    feature_subsets.extend(itertools.combinations(all_features, r))

# Hyperparameter Grid for DecisionTreeClassifier
param_grid = {
    "decisiontreeclassifier__max_depth": [3, 5, 10, 15, None],
    "decisiontreeclassifier__min_samples_split": [2, 5, 10],
    "decisiontreeclassifier__min_samples_leaf": [1, 2, 4]
}

best_score = -1
best_features = None
best_model = None

# Loop through different feature combinations
for feature_set in feature_subsets:
    feature_set = list(feature_set)
    numerical_features = [f for f in feature_set if f in ["Datetime", "AVG"]]
    categorical_features = [f for f in feature_set if f not in ["Datetime", "AVG"]]

    transformer = ColumnTransformer(
        transformers=[
            ("num", StandardScaler(), numerical_features),
            ("cat", OneHotEncoder(handle_unknown="ignore", sparse_output=False), categorical_features)
        ],
        remainder="drop"
    )

    pipeline = Pipeline([
        ("preprocessor", transformer),
        ("decisiontreeclassifier", DecisionTreeClassifier())
    ])

    grid_search = GridSearchCV(
        pipeline,
        param_grid,
        scoring="f1_macro",
        cv=4,
        n_jobs=-1
    )

    grid_search.fit(df_combined[feature_set], df_combined[target])

    if grid_search.best_score_ > best_score:
        best_score = grid_search.best_score_
        best_features = feature_set
        best_model = grid_search.best_estimator_

print("Best Feature Combination:", best_features)
print("Best Parameters:", best_model.named_steps["decisiontreeclassifier"].get_params())
print("Best Cross-Validation Accuracy:", best_score)

import itertools
import pandas as pd
from sklearn.ensemble import RandomForestClassifier
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.model_selection import GridSearchCV

# Feature and target selection
all_features = ["Home Team", "Away Team", "City", "Team", "Datetime", "AVG"]
target = "Home Win"

# Generate feature subsets
feature_subsets = []
for r in range(1, len(all_features) + 1):
    feature_subsets.extend(itertools.combinations(all_features, r))mic

# Hyperparameter grid
param_grid = {
    'randomforestclassifier__n_estimators': [10, 50, 100, 200, 500],
    'randomforestclassifier__max_depth': [None, 10, 20, 30],
    'randomforestclassifier__min_samples_split': [2, 5, 10],
    'randomforestclassifier__min_samples_leaf': [1, 2, 4],
    'randomforestclassifier__max_features': ['sqrt', 'log2'],
    'randomforestclassifier__bootstrap': [True, False]
}

best_score = -1
best_features = None
best_model = None

for feature_set in feature_subsets:
    feature_set = list(feature_set)

    # Split into categorical and numerical
    numerical_features = [f for f in feature_set if f in ["Datetime", "AVG"]]
    categorical_features = [f for f in feature_set if f not in ["Datetime", "AVG"]]

    # Define preprocessing
    transformer = ColumnTransformer(
        transformers=[
            ("num", StandardScaler(), numerical_features),
            ("cat", OneHotEncoder(handle_unknown="ignore", sparse_output=False), categorical_features)
        ],
        remainder="drop"
    )

    # Define pipeline
    pipeline = Pipeline([
        ("preprocessor", transformer),
        ("randomforestclassifier", RandomForestClassifier(random_state=42))
    ])

    # Grid search
    grid_search = GridSearchCV(
        pipeline,
        param_grid,
        scoring="f1_macro",
        cv=4,
        n_jobs=-1
    )

    grid_search.fit(df_combined[feature_set], df_combined[target])

    # Track best combination
    if grid_search.best_score_ > best_score:
        best_score = grid_search.best_score_
        best_features = feature_set
        best_model = grid_search.best_estimator_

print("Best Feature Combination:", best_features)
print("Best Parameters:", best_model.named_steps["randomforestclassifier"].get_params())
print("Best Cross-Validation Accuracy:", best_score)